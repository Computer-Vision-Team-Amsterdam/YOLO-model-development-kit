customer: ""

aml_experiment_details:
  compute_name: oor-testing
  env_name: oor-environment
  env_version: 57
  src_dir: "."

performance_evaluation:
  inputs:
    datastore: "dataset_oor_v2_2"
    ground_truth_rel_path: "processed-dataset-oor-v2-2"
    predictions_rel_path: "inference/v2-2/v2.2"
  outputs:
    datastore: "dataset_oor_v2_2"
    output_rel_path: "evaluation/v2-2/v2.2_test"
  dataset_name: "v2-2"
  model_name: "yolov8m_1280_v2.2"
  ground_truth_image_shape: [3840, 2160]
  predictions_image_shape: [1280, 720]
  prediction_labels_rel_path: "detected_labels"
  splits: ["train", "val", "test"]
  target_classes: [2, 3, 4]
  sensitive_classes: [0, 1]
  target_classes_conf: 0.7  # null means all predictions are used, custom COCO considers this threshold also for sensitive classes
  sensitive_classes_conf: null  # null means all predictions are used, only for TBA evaluation
  plot_pr_curves: True

logging:
  loglevel_own: DEBUG  # override loglevel for packages defined in `own_packages`
  own_packages: ["__main__", "yolo_model_development_kit", "performance_evaluation"]
  basic_config:
    # log config as arguments to `logging.basicConfig`
    level: WARNING
    format: "%(asctime)s|||%(levelname)-8s|%(name)s|%(message)s"
    datefmt: "%Y-%m-%d %H:%M:%S"
  ai_instrumentation_key: "AI_INSTRUMENTATION_KEY"
